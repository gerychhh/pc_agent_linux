OPENAI_BASE_URL=http://127.0.0.1:1234/v1
OPENAI_API_KEY=local

# куда агент шлёт запросы (llama-server OpenAI-compatible)
PC_AGENT_BASE_URL=http://127.0.0.1:1234/v1
PC_AGENT_MODEL_NAME=qwen2.5-7b

# автозапуск llama-server из app.py (если код это поддерживает)
PC_AGENT_AUTOSTART_LLAMACPP=1

# пути к llama-server и модели (GGUF)
LLAMA_SERVER_BIN=third_party/llama.cpp/build/bin/llama-server
LLAMA_SERVER_MODEL=models/Qwen2.5-7B-Instruct-Q4_K_M.gguf

# параметры сервера (под 6GB VRAM начинаем умеренно)
LLAMA_SERVER_PORT=1234
LLAMA_SERVER_CTX=2048
LLAMA_SERVER_N_GPU_LAYERS=20
LLAMA_SERVER_THREADS=8
